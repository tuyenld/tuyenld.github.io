---
layout: post
featured-img: git
title: Fast.ai
categories:
- dl
comments: true
---

# Pending

- [] https://phamdinhkhanh.github.io/2020/06/10/ImageSegmention.html (very good)
- [CNN] [Tìm Hiểu Convolutional Neural Networks Cho Phân Loại Ảnh](https://pbcquoc.github.io/cnn/)
- [CNN] [Quá trình phát triển của CNN từ LeNet đến DenseNet](https://dlapplications.github.io/2018-07-06-CNN/)
- [CNN] [Giới thiệu Mạng nơ-ron tích chập - Convolutional Neural Network](https://dlapplications.github.io/2018-07-17-cnn-introduction/)
- [CNN]\[3b1] [But what is a Neural Network? | Deep learning, chapter 1](https://youtu.be/aircAruvnKk)

# Readme

1. Read chapter > run code > questionare
2. So if you do get stuck on a section, try moving on anyway and make a note to come back to it later.
3. setting yourself four or five **little projects** rather than striving to  solve a big, grand problem tends to work better when you're getting  started
4. focus in learning needs to be on understanding the underlying techniques and how to apply them in practice, and how to quickly build expertise  in new tools and techniques as they are released.
5. DL approach only creates predictions, not recommended actions.  (i.e., attempt to replicate labels)
6. `doc(learn.predict)`

# Q&A

## [01] 

- dataset and model ? we need both ??
- ?
- why two tables ??
    - | epoch | train_loss | valid_loss | error_rate | time  |
      | ----- | ---------- | ---------- | ---------- | ----- |
      | 0     | 0.171341   | 0.026224   | 0.006766   | 00:26 |

      | epoch | train_loss | valid_loss | error_rate | time  |
      | ----- | ---------- | ---------- | ---------- | ----- |
      | 0     | 0.039200   | 0.016735   | 0.009472   | 00:29 |
- This is a positive feedback loop, where the more the model is used, the more biased the data becomes, making the model even more biased, and so forth. ??
	
	- bias ??
- 
# L1

 Deep learning là một loại của Nerural networks 
 DL là một loại của Machine learning

 adding one extra layer -> do anything you want
--> need more layer of neuron

make the game worth playing: làm điều gì đó có nghĩa, kiếm giải thưởng 
work on the hard parts: tìm ra vấn đề, cải tiến nó (đi từ fundamental: đại số, thống kê)
PyTorch (dễ hơn, dùng nhiều hơn ở Academic, 80%) <-> Tensor Flow (sử dụng ít hơn 80->20%) 
Shift+Enter: execute
Note in Github

Juniper notebook: vừa đọc vừa chạy code luôn
Đọc questionare trước : kiến thức take away sau mỗi chapter, hoàn thành trước khi sang chapter mới

File > Trust Notebook 

**weights**: 

- find good weight and update it stochastic gradient descent (SGD)
- called paremeters
- predictions: results
- loss: performance

DL --> only creates *predictions* 
https://youtu.be/_QUEXsHfsA0?t=3870

- valid_pct: over-fitting, used as validation set not as training set (fastai default: 0.2). This 20% of the data is called the validation set; the remaining 80% is called the training set
- Only use technique to avoid over-fitting when u faced it.


- Notice the distinction between the model's results (e.g., the moves in a checkers game) and its performance (e.g., whether it wins the game, or how quickly it wins). 
- Also note that once the model is trained—that is, once we've chosen our final, best, favorite weight assignment—then we can think of the weights as being part of the model, since we're not varying them any more.

Classification and Regression: classification and regression have very specific meanings in machine learning. These are the two main types of model that we will be investigating in this book. A classification model is one which attempts to predict a class, or category. That is, it's predicting from a number of discrete possibilities, such as "dog" or "cat." A regression model is one which attempts to predict one or more numeric quantities, such as a temperature or a location

convolutional neural network (CNN)
A model that has weights that have already been trained on some other dataset is called a pretrained model.
> Transfer learning: Using a pretrained model for a task different to what it was originally trained for.

> Fine-tuning: A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining

## Jargon Recap

| Term             | Meaning                                                      |
| ---------------- | ------------------------------------------------------------ |
| Label            | The data that we're trying to predict, such as "dog" or "cat" |
| Architecture     | The _template_ of the model that we're trying to fit; the actual mathematical function that we're passing the input data and parameters to |
| Model            | The combination of the architecture with a particular set of parameters |
| Parameters       | The values in the model that change what task it can do, and are updated through model training |
| Fit              | Update the parameters of the model such that the predictions of the model using the input data match the target labels |
| Train            | A synonym for _fit_                                          |
| Pretrained model | A model that has already been trained, generally using a large dataset, and will be fine-tuned |
| Fine-tune        | Update a pretrained model for a different task               |
| Epoch            | One complete pass through the input data                     |
| Loss             | A measure of how good the model is, chosen to drive training via "stochastic gradient descent" (SGD) |
| Metric           | A measurement of how good the model is, using the validation set, chosen for human consumption<br /> `learn = cnn_learner(dls, resnet34, metrics=error_rate)` |
| Validation set   | A set of data held out from training, used only for measuring how good the model is |
| Training set     | The data used for fitting the model; does not include any data from the validation set |
| Overfitting      | Training a model in such a way that it _remembers_ specific features of the input data, rather than generalizing well to data not seen during training |
| CNN              | Convolutional neural network; a type of neural network that works particularly well for computer vision tasks |

## Computer Vision task in AI

<iframe frameborder="0" style="width:100%;height:800px;" src="https://viewer.diagrams.net/?highlight=0000ff&layers=1&nav=1&title=Computer%20Vision%20task%20in%20AI.drawio#Uhttps%3A%2F%2Fdrive.google.com%2Fuc%3Fid%3D177gvg3bess2NCFmBYGsoaEl9OsO2t05G%26export%3Ddownload"></iframe>

## Q



1. Do you need these for deep learning?\n",
\n",
   - Lots of math T / F\n",
   - Lots of data T / F\n",
   - Lots of expensive computers T / F\n",
   - A PhD T / F\n",
   \n",
1. Name five areas where deep learning is now the best in the world.\n",
1. What was the name of the first device that was based on the principle of the artificial neuron?\n",
1. Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n",
5. ~~What~~ were the two theoretical misunderstandings that held back the field of neural networks?\n",
   - one layer can't learn
   - one more extra layer -> too big and too slow
6. What is a GPU?\n",
7. Open a notebook and execute a cell containing: `1+1`. What happens?\n",
8. Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.",
9. Complete the [Jupyter Notebook online appendix](https://github.com/fastai/fastbook/blob/master/app_jupyter.ipynb).",
10. Why is it hard to use a traditional computer program to recognize images in a photo?\n",
11. What did Samuel mean by \"weight assignment\"?
    1. current values of the model parameters
    2. automatic change -> get best result
12. What term do we normally use in deep learning for what Samuel called \"weights\"?,
    1. parameters
13. Draw a picture that summarizes Samuel's view of a machine learning model.",
    1. input, weight -> model -> output
14. Why is it hard to understand why a deep learning model makes a particular prediction?\n",
    1. it is hard to determine which factors are important in determining the final output
15. What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?
    1. u*niversal approximation theorem* shows that this function can solve any problem to any level of accuracy, in theory. However, it is important to realize that practically, due to the limits  of available data and computer hardware, it is impossible to practically train a model to do so. But we can get very close!
16. What do you need in order to train a model?
    1. an architecture
    2. data which is labeled
    3. lost function
    4. way to update parameters to improve it performances (optimizer)
17. How could a feedback loop impact the rollout of a predictive policing model?
    1. "arrest" model is used as "crime" model in the practice -> increase police activity -> increase crime -> increase "arrest"
18. Do we always have to use 224×224-pixel images with the cat recognition model?
    1. This is the standard size for historical reasons (old pretrained models  require this size exactly), but you can pass pretty much anything. 
19. What is the difference between classification and regression?
    1. classification: category cat or dog
    2. regression: predict one or more numeric quantities: temperature, or a location
20. What is a validation set? What is a test set? Why do we need them?
    1. validation set: validate set after training
    2. test set: determine effectiveness of the model
21. What will fastai do if you don't provide a validation set?
    1. valid_pct = 0.2
22. Can we always use a random sample for a validation set? Why or why not?
    1. a good validation set should be representative of new data you will see in the future
23. What is overfitting? Provide an example.
    1. model fit too close to a limited set of data but does not generalize unseen data
    2. e.g the need to seperate training, validation and test data
24. What is a metric? How does it differ from \"loss\"?
    1. metric: human-interpretable measures of performance
    2. loss: is meant for SGD to efficiently update the parameter of models
25. How can pretrained models help?
    1. transfer learning
26. What is the \"head\" of a model?
    1. when using pretrained model, the last layer of the model, replaced it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with
27. What kinds of features do the early layers of a CNN find? How about the later layers?
    1. earlier layers learn simple features like diagonal, horizontal, and vertical edge
    2. later layers learn more advanced features like car wheels, flower petals
28. Are image models only useful for photos?
    1. sound when convert it into image
29. What is an \"architecture\"?
    1. template or structure of the model we are trying to fit. 
    2. define mathematicals model we are trying to fit
30. What is segmentation?
    1. predict label for every pixel in the image
31. What is `y_range` used for? When do we need it?
    1. used to limit the value predicted when our problem is focused on numeric value of a given range
32. What are \"hyperparameters\"?
    1. training model requires various other parameter that define how the model is trained
    2. these sorts of parameters is **hyperparameters**
33. What's the best way to avoid failures when using AI in an organization?
    1. make sure training, validation and test set is defined properly in order to evaluate the model in the appropriate manner
    2. try out simple baseline, which future models should hopefully beat. Or even this simple baseline is enough in some cases.



# L2

- We also suggest that you iterate from end to end in your project; don’t spend monthsfine-tuning your model, or polishing the perfect GUI, or labeling the perfect dataset....Instead, complete every step as well as you can in a reasonable amount of time, allthe  way  to  the  end.
- To  make  the  most  of  this  book,  take  the  time  to  experimentbetween  each  chapter,  whether  on  your  own  project  or  by  explor‐ing the notebooks we provide. Then try rewriting those notebooksfrom scratch on a new dataset. It’s only by practicing (and failing) alot that you will develop intuition of how to train a model
- Deep  learning  algorithms  are  generally  not  good  at  recognizing  images  that  are  sig‐nificantly  different  in  structure  or  style  from  those  used  to  train  the  model
- 

## Q

1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the  training data.
	
	> training data: clear bear image; production: bear is behind the tree
2. Where do text models currently have a major deficiency?
3. What are possible negative societal implications of text generation models?
4. In situations where a model might make mistakes, and those mistakes  could be harmful, what is a good alternative to automating a process?
	
	> Human should check a part of process.
5. What kind of tabular data is deep learning particularly good at?
6. What's a key downside of directly using a deep learning model for recommendation systems?
7. What are the steps of the Drivetrain Approach?
8. How do the steps of the Drivetrain Approach map to a recommendation system?
9. Create an image recognition model using data you curate, and deploy it on the web.
10. What is `DataLoaders`?
11. What four things do we need to tell fastai to create `DataLoaders`?
12. What does the `splitter` parameter to `DataBlock` do?
13. How do we ensure a random split always gives the same validation set?
	> Use same seed
14. What letters are often used to signify the independent and dependent variables?
	> independent: x ; dependent: y
15. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?
16. What is data augmentation? Why is it needed?
	> generate new data based on exsisted data by changing color, rotation, contrast
17. What is the difference between `item_tfms` and `batch_tfms`?
18. What is a confusion matrix?
19. What does `export` save?
	> model: architecture and parameter
20. What is it called when we use a model for getting predictions, instead of training?
21. What are IPython widgets?
	> for user to upload data: images
22. When might you want to use CPU for deployment? When might GPU be better?
	> use only one task at a time > CPU; wait for some user than run model > GPU
23. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?
	> need big infrastructure; heavy computation
24. What are three examples of problems that could occur when rolling out a bear warning system in practice?
25. What is "out-of-domain data"?
	> input in practice is very different from input when training model
26. What is "domain shift"?
	> the requirement change, we need to change model ?
27. What are the three steps in the deployment process?